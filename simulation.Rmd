---
title: 'Simulating An RM Study'
output:
  html_document:
    code_download: yes
    fontsize: 8pt
    highlight: textmate
    number_sections: no
    theme: flatly
    toc: yes
    toc_float:
      collapsed: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning =  FALSE)
knitr::opts_chunk$set(fig.width=3.25)
knitr::opts_chunk$set(fig.height=2.75)
knitr::opts_chunk$set(fig.align='center') 
knitr::opts_chunk$set(results='hold') 
```

```{r, echo=FALSE, warning=FALSE}
setwd("C:/Users/tcarse2/Documents/GitHub/Tim_Carsel.github.io")
library(knitr)
library(kableExtra)
library(simr)
library(tidyr)
library(ggplot2)
library(effects)
library(mvtnorm)
library(beepr)
library(effects)
library(MuMIn)
```

\pagebreak

Statistical power is a tricky and occasionally confusing thing. Defined as the probability of rejecting a false null hypothesis, statistical power is a function of the size of the effect of interest, the size of the sample, and the alpha cut-off. 

For simple designs, such as a *t*-test, determining the power of a study is relatively straightforward: Identify the area of the comparison distribution that lies beyond the cut-point defined by alpha. However, for more complicated designs, like those involving repeated measures, determining the power of a study is much more convoluted. Oftentimes, it is necessary to repeatedly simulate the expected results of the study under a variety of conditions. 

Below, I walk you through the simulations and power analyses for my dissertation.

# Setting the Initial Values

For our simulations, we will need to create a sample of generated data. Think of these as computer people who will act in the way we tell them to. These values stay the same throughout all of the simulations except where explicitly mentioned.
```{r}
########################################################
# Setting the seed so this is the same everytime       #
set.seed(10101)                                        #
# Setting the number of subjects to be 5k              #
n1=5000 # Make an even number                          #
# Creating a subject ID number                         #                 
Subject1 = rep(1:n1)                                   #
# Creating the number of repeated measures             #
Sessions1 = rep(1:6)                                   #
# Creates RM design                                    # 
X1 <- expand.grid(Sessions=Sessions1,Subject=Subject1) #
# Add covariate                                        #
impcat<-rep(c(-.5,.5),n1)                              #
X2<-data.frame(impcat=impcat,X1)                       #
# Setting extremely weak relationships                 #
b1 <- c(0,0,.05,-.05,.1,-.15)                          #
########################################################
```

- In the code above, we created a sample of 5000 subjects (Ss) who each have 6 measurements of the criterion variable. 
- Then, we added a between-subjects covariate. In the case of my dissertation, I included a categorical measure of goal importance (Most Important, Least Important) to include in the random structure of the multilevel model. 
- Finally, I initialized the beta values for my eventual model, starting with the intercept, moving through the main effects, and ending with two, two-way interactions. 

As you can see, other than the last interaction, I set my expected betas to be pretty weak. This allowed me to have a conservative estimate of a priori power.

## First Set of Simulations: Varying the covariance between predictors
The degree to which a set of predictors covary affects your ability to reject a false null hypothesis (i.e., it affects your power). In these first three simulations, I am going to change the correlation among my predictors in a principled way and observe how that affects my power.

# Simulation 1
In this first simulation, I will set the correlation between the relevance of the best friend's strength to the goal (hereafter referred to as relevance of strength) and the relevance of the best friend's weakness to the goal (heareafter referred to as relevance to weakness) to be weak and negative.

If people view others at least implicitly as a potential means to goal pursuit (Orehek et al., 2018), then they may differentiate their best friend’s strengths and weaknesses across goals. In other words, it is possible that people will view their friend’s strengths and weaknesses as relevant to different goal contexts. Therefore, in line with this reasoning, I set the correlation between the predictors in this first simulation to be weak and negative (-0.10).

```{r}
##########################################################
##########################################################
###################### Simulation 1 ######################
###  Setting weak predictor and changing correlations  ###
########## Correlation between predictors = -.1 ##########
##########################################################
# Setting weak negative
sigma <- matrix(c(1,-.1,
                -.1,  1), ncol=2)

# Creating predictors
x <- rmvnorm(n=n1, mean=c(0,0), sigma=sigma)

relstrength<-x[,1]
relweak<-x[,2]
# Checking correlation between predictors
cor(x)
```
```{r}
# Creating dataframe
X3<-data.frame(relstrength=relstrength,relweak=relweak,X2)

###############################
######## Simulation 1a ########
###############################
# Random intercept and random slope of importance
Sub <-diag(c(.6,.2))

# Setting cov between slope and intercept
Sub[lower.tri(Sub)] <- .05

# Setting residual variance
s <- (1-(sum(Sub)))^.5 
# Checking
s # Residual s2=.15 
```


Let's check to make sure the multiple R^2 of the model makes sense.
```{r}
# Finish Triangle for random items
Sub[upper.tri(Sub)] <- .05

# Generating the simulation
SimInter1 <- makeLmer(DV ~ impcat+relstrength+relweak+impcat:relstrength+impcat:relweak +(1+impcat|Subject), 
                      fixef=b1, VarCorr=list(Sub), sigma=s, data=X3)

#Check sim
summary(SimInter1)

# Check R2 - extract one model fit
Test.Data<-getData(SimInter1)

# Checking the fixed R2 for the predictor
R2.test<-r.squaredGLMM(SimInter1)
R2.test[,1] # 1.7%
```


Here's the effect size in Rho.
```{r}
# Rho
R2.test[,1]^.5
```


And in Cohen's *d*.
```{r}
# Cohen's d 
d= (2*R2.test[,1]^.5) / (1-R2.test[,1])^.5
d # .27
```


Now, let's extract one sample of the simulation and run our analysis on it to ensure it's working properly.
```{r}
# Extracting test data to run sample primary analysis
Test.Data<-getData(SimInter1)

# Sample primary analysis
T1<-lmer(DV ~ impcat+relstrength+relweak+impcat:relstrength+impcat:relweak +(1+impcat|Subject),
         data=Test.Data, REML=F)
summary(T1)
```
Yep. That went the way we expected it!


Here's the expected relationship between the relevance to strength and importance on interpersonal trust.
```{r, , echo=FALSE, out.width='.49\\linewidth', fig.width=2.25, fig.height=2.5,fig.show='hold',fig.align='center'}
# Plotting interaction between importance and the relevance of the friend's strength to the goal
Final.Fixed<-effect(c("impcat*relstrength"), T1,
                    xlevels=list(impcat=c(-.5,+.5),
                    relstrength=seq(-2,+2,.5)))

# Converting to dataframe
Final.Fixed<-as.data.frame(Final.Fixed)
# Recoding as factor
Final.Fixed$impcatF<-as.factor(Final.Fixed$impcat)

#########################################################
### Plotting Primary Analysis: RelStrength*Importance ###
#########################################################
Final.Fixed.Plot <-ggplot(data = Final.Fixed, aes(x = relstrength, y =fit, group=impcatF))+
  geom_line(aes(color=impcatF), size=2)+
  geom_ribbon(aes(ymin=fit-se, ymax=fit+se,fill=impcatF),alpha=.2)+
  xlab("Relevance to Strength")+
  ylab("Trust")+
  scale_color_manual(values=c("blue", "red"))+
  scale_fill_manual(values=c("blue", "red"))+
  theme_bw()+
  theme(text=element_text(face="bold", size=12),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        panel.border = element_rect(fill = NA, colour = "NA"),
        axis.line = element_line(size = 1, colour = "grey80"),
        legend.title=element_blank(),
        legend.position = c(.2, .92))
Final.Fixed.Plot
```


Here's the expected power at N = 100, 150, 200, 250, 300, 400, and 500 for the interaction.
```{r,echo=FALSE,results="hide"}
### Power simulation for RelStrength Interaction 1 ###
SCurve1<-powerCurve(SimInter1, fixed("impcat:relstrength", "lr"),
                    along = "Subject",
                    breaks = c(100,150,200,250,300,400,500),
                    nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve1
plot(SCurve1)
```



And here's the expected relationship between the relevance to weakness and importance on interpersonal trust.
```{r}
#####################################################
### Plotting Primary Analysis: RelWeak*Importance ###
#####################################################
Final.Fixed2<-effect(c("impcat*relweak"), T1,
                     xlevels=list(impcat=c(-.5,+.5),
                     relweak=seq(-2,+2,.5)))

# Converting to a dataframe
Final.Fixed2<-as.data.frame(Final.Fixed2)
# Recoding as factor
Final.Fixed2$impcatF<-as.factor(Final.Fixed2$impcat)

# Plotting
Final.Fixed.Plot2 <-ggplot(data = Final.Fixed2, aes(x = relweak, y =fit, group=impcatF))+
  geom_line(aes(color=impcatF), size=2)+
  geom_ribbon(aes(ymin=fit-se, ymax=fit+se,fill=impcatF),alpha=.2)+
  xlab("Relevance to Weakness")+
  ylab("Trust")+
  scale_color_manual(values=c("blue", "red"))+
  scale_fill_manual(values=c("blue", "red"))+
  theme_bw()+
  theme(text=element_text(face="bold", size=12),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        panel.border = element_rect(fill = NA, colour = "NA"),
        axis.line = element_line(size = 1, colour = "grey80"),
        legend.title=element_blank(),
        legend.position = c(.2, .92))
Final.Fixed.Plot2
```



Here's the expected power at N = 100, 150, 200, 250, 300, 400, and 500 for the interaction.
```{r,echo=FALSE,results="hide"}
### Power simulation for RelWeak Interaction 1 ###
SCurve2<-powerCurve(SimInter1, fixed("impcat:relweak", "lr"),
                     along = "Subject",
                     breaks = c(100,150,200,250,300,400,500),
                     nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve2
plot(SCurve2)

```

# Simulation 2
In contrast to the potential situation just characterized, whereby people were expected to view their friend’s strengths and weaknesses as weakly and negative related, the next simulation estimates the effect of friend attributes’ goal relevance being positive correlated. In the study’s design, participants were first asked to identify and describe their personal projects and then to identify and describe their best friend. Therefore, the methods pressed for participants to imagine their personal projects, free from whom they may choose to rely upon. Consequently, it seemed possible that the same constellation of friend attributes may be perceived as both a strength and a weakness and relevant to similar situations. For example, perhaps Tim believes that Andy is a “free spirit.” Consequently, he may believe that Andy’s biggest strength is that he is good at generating novel solutions to problems, but Tim may believe Andy’s greatest weakness is that he is unreliable. To model this potential outcome in Simulation 2, I set a moderate and positive (0.40) correlation between the relevance of the best friends’ strengths and weaknesses to the goal.


```{r, echo=FALSE,results="hide"}
# Resetting seed
set.seed(10101)

###############################
######## Simulation 1b ########
###############################
# Setting strong positive relationship between predictors
## to control for potential effect of collinearity on power
sigma1b <- matrix(c(1,.4,
                  .4 ,1), ncol=2)
# Creating predictors
x2b <- rmvnorm(n=n1, mean=c(0,0), sigma=sigma1b)

# Creating new predictors with strong positive correlation
relstrength1b<-x2b[,1]
relweak1b<-x2b[,2]

# Creating new dataframe
X3b<-data.frame(relstrength=relstrength1b,relweak=relweak1b,X2)

# Generates the simulation
SimInter1b <- makeLmer(DV ~ impcat+relstrength+relweak+impcat:relstrength+impcat:relweak +(1+impcat|Subject), 
                      fixef=b1, VarCorr=list(Sub), sigma=s, data=X3b)

### Power simulation for RelStrength Interaction 1b ###
SCurve1b<-powerCurve(SimInter1b, fixed("impcat:relstrength", "lr"),
                    along = "Subject",
                    breaks = c(100,150,200,250,300,400,500),
                    nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve1b
plot(SCurve1b)
```


```{r,echo=FALSE,results="hide"}
### Power simulation for RelStrength Interaction 1b ###
SCurve2b<-powerCurve(SimInter1b, fixed("impcat:relweak", "lr"),
                     along = "Subject",
                     breaks = c(100,150,200,250,300,400,500),
                     nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve2b
plot(SCurve2b)

```

# Simulation 3
In Simulation 3, I set a strong and positive (0.80) correlation between the relevance of the best friends’ strengths and weaknesses to the goal. This would be a worst-case scenario, not simply because of multicollinearity issues but because my predictions the effect of the relevance to strength and relevance to weakness on trust were in the opposite directions. Consequently, if Simulation 3 was true, then my hypotheses would certainly not be supported.

```{r}
set.seed(10101)

###############################
######## Simulation 1c ########
###############################
# Setting very strong positive relationship between predictors
sigma1c <- matrix(c(1,.8,
                   .8, 1), ncol=2)
# Creating new predictors
x2c <- rmvnorm(n=n1, mean=c(0,0), sigma=sigma1c)
relstrength1c<-x2c[,1]
relweak1c<-x2c[,2]

# Create dataframe
X3c<-data.frame(relstrength=relstrength1c,relweak=relweak1c,X2)


# Generates the simulation
SimInter1c <- makeLmer(DV ~ impcat+relstrength+relweak+impcat:relstrength+impcat:relweak +(1+impcat|Subject), 
                      fixef=b1, VarCorr=list(Sub), sigma=s, data=X3c)
```



```{r,echo=FALSE,results="hide"}
# Power simulation for relstrength
SCurve1c<-powerCurve(SimInter1c, fixed("impcat:relstrength", "lr"),
                    along = "Subject",
                    breaks = c(100,150,200,250,300,400,500),
                    nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve1c
plot(SCurve1c)
```



```{r,echo=FALSE,results="hide"}
# Power simulation for relweakness
SCurve2C<-powerCurve(SimInter1c, fixed("impcat:relweak", "lr"),
                     along = "Subject",
                     breaks = c(100,150,200,250,300,400,500),
                     nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve2C
plot(SCurve2C)
```

# Increasing the Residual Variance
The second two simulations (M4, M5) modeled the effect of increasing the residual variance in the models on a priori power. Specifically, the total random variance was set to 1 and was allocated between the variance attributed to the random intercept, the random slope, the correlation between the random intercept and the slope, and the residual. In the first three models a large proportion of the variance was attributed to the random intercept (0.60), followed by the random slope (0.20), the residual (0.15), and the correlation between the random intercept and the slope (0.05). This specification assumes that much of the variability in trust is attributable to the individual’s general level of trust for their best friend. In other words, these models account for the fact that people really do tend to trust at varying levels (e.g., Rotter, 1980).

## Simulation 4
In M4, the amount of variance attributed to the random intercept was decreased to 0.40. Because the random intercept was allocated most of the random variance, it was the easiest term to reduce while ensuring interpretability between previous models. Moreover, it’s initial setting represented the more unrealistic parameter setting because it assumed 60% of the random variance was attributable to average levels of trust between individuals. The result of this change was that the residual variance was increased from 0.15 to 0.35 for M4.

```{r}
set.seed(10101)

###############################
######## Simulation 2a ########
###############################
# Decreasing variance of random intercept and ranmdom slope of importance to increase residuals
Sub2 <-diag(c(.4,.2))

# Setting cov between slope and intercept
Sub2[lower.tri(Sub)] <- .05

# Setting residual sd
s2 <- (1-(sum(Sub2)))^.5 

# Finish Triangle for random items
Sub2[upper.tri(Sub2)] <- .05

# Generating the simulation using the values generated from Sim 1 with increased residuals
SimInter2 <- makeLmer(DV ~ impcat+relstrength+relweak+impcat:relstrength+impcat:relweak +(1+impcat|Subject), 
                      fixef=b1, VarCorr=list(Sub2), sigma=s2, data=X3b)
```



```{r,echo=FALSE,results="hide"}
### Power simulation for RelStrength Interaction 2 ###
SCurve1<-powerCurve(SimInter2, fixed("impcat:relstrength", "lr"),
                    along = "Subject",
                    breaks = c(100,150,200,250,300,400,500),
                    nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve1
plot(SCurve1)
```



```{r,echo=FALSE,results="hide"}
### Power simulation for RelWeak Interaction 1 ###
SCurve2<-powerCurve(SimInter2, fixed("impcat:relweak", "lr"),
                     along = "Subject",
                     breaks = c(100,150,200,250,300,400,500),
                     nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve2
plot(SCurve2)

```

## Simulation 5
In M5, I further reduced the amount of variance attributable to the random intercept to 0.20. This model assumes that the majority of the random variance is attributable to the residual and is therefore left unpredicted (0.55). However, the random intercept is kept as one of the most predictive specified term in the random structure, but in M5 it is assumed to be equivalent to the random slope between goal importance and trust.

```{r}
set.seed(10101)

###############################
######## Simulation 2b ########
###############################
# Decreasing variance of random intercept and ranmdom slope of importance to increase residuals
Sub2b <-diag(c(.2,.2))

# Setting cov between slope and intercept
Sub2b[lower.tri(Sub)] <- .05

# Setting residual sd
s2b <- (1-(sum(Sub2b)))^.5 
# Finish Triangle for random items
Sub2b[upper.tri(Sub2b)] <- .05

# Generating the simulation using the values generated from Sim 1b
SimInter2b <- makeLmer(DV ~ impcat+relstrength+relweak+impcat:relstrength+impcat:relweak +(1+impcat|Subject), 
                      fixef=b1, VarCorr=list(Sub2b), sigma=s2b, data=X3b)
```



```{r,echo=FALSE,results="hide"}
### Power simulation for RelStrength Interaction 2 ###
SCurve1b<-powerCurve(SimInter2b, fixed("impcat:relstrength", "lr"),
                    along = "Subject",
                    breaks = c(100,150,200,250,300,400,500),
                    nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve1b
plot(SCurve1b)
```



```{r,echo=FALSE,results="hide"}
### Power simulation for RelWeak Interaction 1 ###
SCurve2b<-powerCurve(SimInter2b, fixed("impcat:relweak", "lr"),
                    along = "Subject",
                    breaks = c(100,150,200,250,300,400,500),
                    nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve2b
plot(SCurve2b)
```

# The Study Goes to Hell

## Simulation 6
In my final model (M6), I use all of the parameter settings that decrease a priori power. Specifically, I set the correlation between my predictors to be 0.80, and I set my residual variance to be 0.55 by setting my random intercept term at 0.20, my random slope term at 0.20, and the variance attributed to the correlation between my random slope and intercept at 0.05. The parameters of M6 are unlikely because they assume that the fixed effects in my study are not predictive of trust, that participants will view their best friend’s strength and weakness as equivalently relevant across goals, and that the residual variance will account for 55% of the random variance (as opposed to the average level of trust between participants, the slope between goal importance and trust between participants, and the correlation between these two random terms). Therefore, this model’s estimate represents a lower bound on my expected power.

```{r}
#################################################################################
################################# Simulation 3 ##################################
###  Setting weak predictor, high residuals, and strong positive correlation  ###
#################################################################################

# Generating the simulation
SimInter3 <- makeLmer(DV ~ impcat+relstrength+relweak+impcat:relstrength+impcat:relweak +(1+impcat|Subject), 
                      fixef=b1, VarCorr=list(Sub2b), sigma=s2b, data=X3c)
```



```{r,echo=FALSE,results="hide"}
### Power simulation for RelStrength Interaction 1 ###
SCurve3<-powerCurve(SimInter3, fixed("impcat:relstrength", "lr"),
                    along = "Subject",
                    breaks = c(100,150,200,250,300,400,500),
                    nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve3
plot(SCurve3)
```



```{r,echo=FALSE,results="hide"}
### Power simulation for RelWeak Interaction 1 ###
SCurve3b<-powerCurve(SimInter3, fixed("impcat:relweak", "lr"),
                    along = "Subject",
                    breaks = c(100,150,200,250,300,400,500),
                    nsim=500,alpha=.045, progress=TRUE)
```



```{r}
SCurve3b
plot(SCurve3b)
```


# Graphing power of N = 400 across all simulations
```{r}
Power400S<-c(100, 100, 88.8, 92.4, 80.2, 45)
Power400w<-c(100, 100, 99.8, 100, 98.4, 78)
```


Here's the expected power at N = 400 for the interaction between the relevance to strength and importance across all 6 simulations.
```{r,echo=FALSE}
plot(Power400S, type= "b", xlab="Expected Power", ylab="Simulation")
```


And here's the expected power at N = 400 for the interaction between the relevance to weakness and importance across all 6 simulations.
```{r,echo=FALSE}
plot(Power400w, type= "b", xlab="Expected Power", ylab="Simulation")

```

Notice the second interaction has more power at pretty much every simulation? That's because we set the interaction including the relevance to weakness to be *b* = -0.15 whereas we set the interaction including the relevance to strength to be *b* = +0.10. That 5/100 increase made a huge difference!